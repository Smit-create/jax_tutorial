{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3012f814",
   "metadata": {},
   "source": [
    "# Lecture 4: Vectorization and Parallelization in JAX\n",
    "\n",
    "## Introduction to Vectorization\n",
    "\n",
    "Vectorization is a technique used in numerical computing to perform operations on entire arrays or batches of data simultaneously, leveraging the inherent parallelism of modern hardware. By operating on vectors or arrays rather than individual elements, vectorized code can achieve significant performance improvements, especially when dealing with large datasets or computational tasks. In JAX, vectorization plays a crucial role in optimizing computations for efficiency and scalability.\n",
    "\n",
    "Writing fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\n",
    "\n",
    "This procedure is called **vectorization** or **array programming**, and will be familiar to anyone who has used NumPy.\n",
    "\n",
    "In most ways, vectorization is the same in JAX as it is in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e2f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81742f",
   "metadata": {},
   "source": [
    "### Writing Vectorized Code in JAX\n",
    "\n",
    "Vectorized code in JAX can be written using JAX's NumPy-like API, which supports operations on arrays and tensors. By expressing computations in terms of array operations, such as element-wise arithmetic, matrix multiplication, and broadcasting, developers can harness the full potential of vectorization in JAX.\n",
    "\n",
    "Let's illustrate this with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca731d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared elements: [ 1  4  9 16 25]\n"
     ]
    }
   ],
   "source": [
    "# Define a vectorized computation to calculate the element-wise square of an array\n",
    "def square_elements(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Apply the vectorized computation to an array\n",
    "input_array = jnp.array([1, 2, 3, 4, 5])\n",
    "result_array = square_elements(input_array)\n",
    "print(\"Squared elements:\", result_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d5179",
   "metadata": {},
   "source": [
    "But there are also some differences, which we highlight here.\n",
    "\n",
    "As a running example, consider the function\n",
    "\n",
    "$$\n",
    "f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n",
    "$$\n",
    "\n",
    "Suppose that we want to evaluate this function on a square grid of $ x $ and $ y $ points and then plot it.\n",
    "\n",
    "To clarify, here is the slow `for` loop version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32306e7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def f(x, y):\n",
    "    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "n = 80\n",
    "x = jnp.linspace(-2, 2, n)\n",
    "y = x\n",
    "\n",
    "z_loops = np.empty((n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02f63ae",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 7.26 ms, total: 1.16 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        z_loops[i, j] = f(x[i], y[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85880a69",
   "metadata": {},
   "source": [
    "Even for this very small grid, the run time is extremely slow.\n",
    "\n",
    "(Notice that we used a NumPy array for `z_loops` because we wanted to write to it.)\n",
    "\n",
    "OK, so how can we do the same operation in vectorized form?\n",
    "\n",
    "If you are new to vectorization, you might guess that we can simply write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70392f1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "z_bad = f(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063d93b",
   "metadata": {},
   "source": [
    "But this gives us the wrong result because JAX doesn’t understand the nested for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc646ef",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_bad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb643d",
   "metadata": {},
   "source": [
    "Here is what we actually wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76356ca7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_loops.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e6663",
   "metadata": {},
   "source": [
    "To get the right shape and the correct nested for loop calculation, we can use a `meshgrid` operation designed for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3db1c31",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x_mesh, y_mesh = jnp.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc1de3",
   "metadata": {},
   "source": [
    "Now we get what we want and the execution time is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec347481",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 1.03 ms, total: 12.2 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc57a149",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 µs, sys: 32 µs, total: 147 µs\n",
      "Wall time: 140 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263927a5",
   "metadata": {},
   "source": [
    "Let’s confirm that we got the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fac39c5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(z_mesh, z_loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa30f43",
   "metadata": {},
   "source": [
    "Now we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601e4a58",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "n = 6000\n",
    "x = jnp.linspace(-2, 2, n)\n",
    "y = x\n",
    "x_mesh, y_mesh = jnp.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c731aea6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 ms, sys: 17.3 ms, total: 131 ms\n",
      "Wall time: 53.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cd3443",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 18.1 ms, total: 122 ms\n",
      "Wall time: 44.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_mesh = f(x_mesh, y_mesh) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3c93c",
   "metadata": {},
   "source": [
    "But there is one problem here: the mesh grids use a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e27dce7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mesh.nbytes + y_mesh.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d809b0",
   "metadata": {},
   "source": [
    "By comparison, the flat array `x` is just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6d8184",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.nbytes  # and y is just a pointer to x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a76f1",
   "metadata": {},
   "source": [
    "This extra memory usage can be a big problem in actual research calculations.\n",
    "\n",
    "### Using `jax.vmap`\n",
    "\n",
    "So let’s try a different approach using [jax.vmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html)\n",
    "\n",
    "#### Converting loops to `jax.vmap`\n",
    "\n",
    "The process of converting loops to `jax.vmap` is simple. You take the inner most loop\n",
    "and vectorized your code over this loop and start forming a nested sequence of `jax.vmap`\n",
    "from inner most loop to outer most.\n",
    "\n",
    "Here in our example, first we vectorize `f` in `y` because `y` is in the inner loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447d59c4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f_vec_y = jax.vmap(f, in_axes=(None, 0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebd432",
   "metadata": {},
   "source": [
    "In the line above, `(None, 0)` indicates that we are vectorizing in the second argument, which is `y`.\n",
    "\n",
    "Next, we vectorize in the first argument, which is `x` and used in the outer loop using\n",
    "`f_vec_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c367656",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "f_vec = jax.vmap(f_vec_y, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ca509",
   "metadata": {},
   "source": [
    "With this construction, we can now call the function $ f $ on flat (low memory) arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b67524b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 13.6 ms, total: 124 ms\n",
      "Wall time: 50.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_vmap = f_vec(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1442b0e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 16.3 ms, total: 118 ms\n",
      "Wall time: 42.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "z_vmap = f_vec(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "613a526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 6000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_vmap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65276a7",
   "metadata": {},
   "source": [
    "The execution time is essentially the same as the mesh operation but we are using much less memory.\n",
    "\n",
    "And we produce the correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e8432f7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(z_vmap, z_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198b74b",
   "metadata": {},
   "source": [
    "#### Benefits of Vectorization with jax.vmap\n",
    "\n",
    "Vectorizing computations with `jax.vmap` offers several benefits:\n",
    "\n",
    "- **Improved Performance**: Vectorized code can leverage hardware parallelism for faster execution, especially on accelerators like GPUs and TPUs.\n",
    "- **Simplified Code**: By replacing nested loops with array operations, vectorized code tends to be more concise, readable, and maintainable.\n",
    "- **Scalability**: Vectorization enables scaling computations to larger datasets or batch sizes without significant performance degradation, making it suitable for machine learning tasks and scientific computing.\n",
    "- **Nested Vmaps**: Once can easily replace a sequence of python loops using a sequence of `jax.vmap` and JAX handles all the optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8b6ca",
   "metadata": {},
   "source": [
    "## Introduction to parallelization\n",
    "\n",
    "Parallelization is a crucial technique for accelerating computations by leveraging the parallelism of modern hardware. In JAX, parallelization can be achieved using `jax.pmap` for parallel mapping and `jax.pjit` for parallel just-in-time compilation. This lecture will explore these constructs in detail, demonstrating how they enable efficient parallel execution on multi-core CPUs and GPUs.\n",
    "\n",
    "### Parallel Mapping with `jax.pmap`\n",
    "\n",
    "`jax.pmap` is a higher-order function in JAX that parallelizes a function across multiple devices or processors. It maps the function over the leading axis of the input arrays and executes the function in parallel on each device. This enables efficient parallel execution of computations, particularly on GPUs or multi-core CPUs.\n",
    "\n",
    "#### Using `jax.pmap`\n",
    "\n",
    "Let's illustrate the usage of [jax.pmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html) with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "138efae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to square each element of an array\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Parallelize the function using jax.pmap\n",
    "parallel_square = jax.pmap(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10ceecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared elements (parallel): [0]\n"
     ]
    }
   ],
   "source": [
    "# Apply the parallelized function to an array\n",
    "num_available_devices = jax.local_device_count()\n",
    "\n",
    "input_array = jnp.arange(num_available_devices)\n",
    "\n",
    "result_array = parallel_square(input_array)\n",
    "print(\"Squared elements (parallel):\", result_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bf0ab",
   "metadata": {},
   "source": [
    "The output is just `[0]` because `num_available_devices` on my device is just 1. In case\n",
    "you are working on a machine having large number of GPUs/TPUs you can easily use `jax.pmap`\n",
    "to parallelize your execution. The only note while using `pmap` is that:\n",
    "\n",
    "The mapped `axis` size must be less than or equal to the number of local XLA devices available, as returned by `jax.local_device_count()` (unless devices is specified, see below). For nested `pmap` calls, the product of the mapped axis sizes must be less than or equal to the number of XLA devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46614f2",
   "metadata": {},
   "source": [
    "### Benefits of Parallelization with JAX\n",
    "\n",
    "- **Performance**: Parallelization enables efficient utilization of hardware resources, leading to faster execution times for computations.\n",
    "- **Scalability**: With parallel execution, computations can scale to larger datasets and models, accommodating the growing demands of machine learning and scientific computing tasks.\n",
    "- **Hardware Utilization**: JAX maximizes hardware utilization by leveraging multi-core CPUs and GPUs for parallel execution, improving overall efficiency and productivity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
